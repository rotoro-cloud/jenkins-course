---
layout: article
---
Особенность этого подхода в том, что вызов второй job происходит непосредственно из первой. Кроме вызова, первая job также получает результат вызванной сборки и учитывает его при своём исполнении. Таким образом это будет **зависимое** исполнение. Результат первой сборки будет зависеть от результата второй. И на самом деле это тоже настраивается, поскольку Jenkins очень гибкий.

Давай попробуем сами. У меня есть четвертый пайплайн, он называется `dns`. Я бы хотел, чтобы во время исполнения сборки конвейера `deploy` был вызван пайплайн `dns`, и, если в зависимом конвейере все прошло успешно, то `deploy` продолжил бы работать.

Еще раз. Мы вызываем `dns` из `deploy`. И здесь запущенный конвейер как бы становится частью конвейера, его запустившего.

```
pipeline {
    agent any

    stages {
        stage('Hello') {
            steps {
                echo 'Pre deploy'
            }
        }
    }
}

```

В отличие от предыдущих, в этом пайплайне нам ничего не требуется настраивать. Вместо этого нам нужно настроить задание, из которого будет вызван этот. У нас это конвейер `deploy`.

Здесь, в разделе конфигурирования `deploy` я перейду в генератор директив и выберу `Sample Step` как `Build a job`. В боксе нужно ввести имя job, которую нужно запустить. Как ты помнишь, мы хотим вызвать сборку `dns` из сборки `deploy`. Поэтому здесь я пишу `dns`. В триггерах с `upstream` мы делали это наоборот.

Нажимаю на создание скрипта. После копирую его и перехожу к редактированию пайплайна `deploy`:

```
pipeline {
    agent any
    triggers {
        upstream 'build, '
    }

    stages {

        stage('trigger dns') {
            steps {
                build 'dns'
            }
        }
    }

    stages {
        stage('Hello') {
            steps {
                echo 'Deploy app'
            }
        }
    }
}

```

Я добавил новую стадию `trigger dns`, в шаги которой вставил скопированную директиву `build`. Теперь сохраняю и просто запускаю job `deploy`.

Как видишь, в логах сначала появилась надпись `Scheduling project`, а далее название задания - `dns`. После завершения идет стадия `Hello`, которая выводит, что произошел деплой.

В логах `dns`, мы можем увидеть, что ее исполнение инициировал `upstream project "deploy"` с номером сборки 2, начатый пользователем `admin`. На слайдах у меня этого нет, можешь проверить сам.

Наконец, давай проверим зависимость `deploy` от `dns`. Я зайду в редактирование `dns` и добавлю еще один шаг с командой `sh "exit 1"`. Это вызывает команду, возвращающую ненулевой код ошибки. Следовательно, все сборки пайплайна `dns` после этого будут провалены. Сохраню и запущу задание `deploy`.

В логах я опять вижу картину, что внутри `deploy` запустился `dns`, но в этот раз стадия `Hello` была пропущена из-за предыдущего падения. Это упал наш **downstream job**, а его результат был передан в вызывающую сборку. Таким образом и вызывающая сборка стала зафейленой.
